{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 2, Solution\n",
    "**Stats 507, Fall 2021**\n",
    "*Dingyu Wang*\n",
    "*September 28, 2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The remaining questions will use the following imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# modules: --------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections \n",
    "import re\n",
    "from timeit import Timer\n",
    "from IPython.core.display import display, HTML\n",
    "# 79: -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Quesiton 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]]\n",
    "    for n in range(len(sample_list)):\n",
    "        if (sample_list[m][0] == sample_list[n][0] and\n",
    "                sample_list[m][2] != sample_list[n][2]):\n",
    "            li.append(sample_list[n])\n",
    "    op.append(sorted(li, key=lambda dd: dd[2], reverse=True)[0])\n",
    "res = list(set(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### a) What task the code above accomplishes\n",
    "The code will scratch the tuple from sample_list with two types: the first type is the tuple whose first element is unique among the whole sample_list, the second type is the tuple with the first elements is equal to another tuple and the third element is the biggest (or share the same maximum with other tuple) among all the tuple with the same first element in the sample_list. Finally, the function will eliminate  the same tuple it scratched and output a list with tuples (the output order is unordered, which may varies between different running environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### b) Code review\n",
    "* Indice out of range.\n",
    "* For loop indentation error.\n",
    "* Iterate over indices only when necessary, else iterate over values.\n",
    "* There is no need to creat a new list res.\n",
    "* Try to apply list comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this question, we write a function uses list comprehension to generate a random list of n k-tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def generate_list(n, k = 10, low = 0, high = 10):\n",
    "    '''\n",
    "    generate a random list of n k-tuples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The length of the list.\n",
    "    k : int, optional\n",
    "        The length of the tuple.\n",
    "    low : int, optional\n",
    "        The lower bond of generated number.\n",
    "    high : int, optional\n",
    "        The upper bond of generated number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list contains n k-tuples.\n",
    "    '''\n",
    "    return ([tuple([np.random.randint(low, high+1)\n",
    "                    for i in range(k)]) for j in range(n)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this part we use `assert` to test if `generate_list()` returns a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function does return a list of tuple\n"
     ]
    }
   ],
   "source": [
    "test = generate_list(20)\n",
    "assert(isinstance(test,list)),\"The function doesn't return a list of tuple\"\n",
    "for m in test:\n",
    "    assert(isinstance(m,tuple)), \"The function doesn't return a list of tuple\"\n",
    "print(\"The function does return a list of tuple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this question we will write several functions to accomplish the goal that code in Question 0 does. And a Monte carlo simulation is applied to compare the execution times of each functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### a) tup_for()\n",
    "This function is totally a copy of the code in Question 0, we only encapsulate it into a function, with input `a` represent the first indices, `b` represent the second indices and `sample_list` represent the list we cope with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def tup_for(a,b,sample_list):\n",
    "    '''\n",
    "    Apply for loop to select tuples in a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int\n",
    "        The first indices\n",
    "    b : int\n",
    "        The second indices\n",
    "    sample_list : list\n",
    "        The list with n k-tuples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list contains selected tuple.\n",
    "    '''\n",
    "    op = []\n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][a] == sample_list[n][a] and\n",
    "                    sample_list[m][b] != sample_list[n][b]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[b], reverse=True)[0])\n",
    "    res = list(set(op))\n",
    "    return res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### b) tup_for_adv()\n",
    "In this function I apply the advice in code review to make the code more efficient and literate. Specifically, I use list comprehensions instead of simple for loop, iterate the list over values instead of indices and avoid redundant list generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def tup_for_adv(a,b,sample_list):\n",
    "    '''\n",
    "    An advanced function using for loop to select tuples in a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int\n",
    "        The first indices\n",
    "    b : int\n",
    "        The second indices\n",
    "    sample_list : list\n",
    "        The list with n k-tuples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list contains selected tuple.\n",
    "    '''\n",
    "    op = []\n",
    "    for m in sample_list:\n",
    "        li = [m]\n",
    "        li.extend([n for n in sample_list if (m[a] == n[a] and m[b] != n[b])])\n",
    "        op.append(sorted(li, key=lambda dd: dd[b], reverse=True)[0])\n",
    "    op = list(set(op))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### c) tup_dict()\n",
    "I use nested dictionaries to achieve the goal of the code in Question 0. Specifically, I use defaultdict to generate nested dictionary. The keys in outer dictionary will store the first indices of each tuple, the keys in inner dictionary will store the second indices of each tuple, and the values in inner dictionary will calculate the number of tuples with the first and second indices corresponding to the values of keys in the dictionary. In this way, we can calculate the number of tuples we want and do the following step.\n",
    "\n",
    "In this function I apply two independent for loop with sample_list. The first for loop is to transmit the information from sample_list to dictionary, the second for loop is to indices the sample_list according to our dictionary. List comprehension is also used to make the code more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def tup_dict(a,b,sample_list):\n",
    "    '''\n",
    "    Apply dictionary to select tuples in a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int\n",
    "        The first indices\n",
    "    b : int\n",
    "        The second indices\n",
    "    sample_list : list\n",
    "        The list with n k-tuples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list contains selected tuple.\n",
    "    '''\n",
    "    d = collections.defaultdict(dict)\n",
    "    for m in sample_list:                                   # First for loop\n",
    "        d[m[a]] = (d.get(m[a]) if m[a] in d else collections.defaultdict(int))\n",
    "        d[m[a]][m[b]] = (d.get(m[a]).get(m[b]) \n",
    "                         if m[b] in d.get(m[a]) else 0) + 1 \n",
    "    li = []\n",
    "    for k,v in d.items():\n",
    "        if len(v) == 1:\n",
    "            for e in v.keys():\n",
    "                li.extend([(k, e)])\n",
    "        else:\n",
    "            li.extend([(k,sorted(v, reverse = True)[0])])\n",
    "    op = []\n",
    "    for m in sample_list:                                   # First for loop\n",
    "        op.extend([m for j in li if (m[a]==j[0] and m[b]==j[1])])\n",
    "    op = list(set(op))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### d) Comparisons\n",
    "In this part I will generate different sample_list to compare the execution time of each funtion. In turns of each $n=10, 100, 1000, 10000$, every functions will execute 10 times and calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# timing comparisons: ---------------------------------------------------------\n",
    "res = collections.defaultdict(list)\n",
    "n = [10,100,1000,10000]\n",
    "res['n'] = n\n",
    "for k in n:\n",
    "    for f in (tup_for, tup_for_adv, tup_dict):\n",
    "        t = Timer(\"f(a,b,n)\", \n",
    "                  globals={\"f\": f, \"a\": 0, \"b\": 3, \"n\": generate_list(k)})\n",
    "        m = np.mean([t.timeit(1) for i in range(10)])\n",
    "        res[f.__name__].append(round(m,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# construct a table, include a caption: ---------------------------------------\n",
    "cap = \"\"\"\n",
    "<b> Table 1.</b> <em> Timing comparisons for tuple selection functions.</em>\n",
    "Mean computation times.\n",
    "\"\"\"\n",
    "res = pd.DataFrame(res)\n",
    "t1 = res.to_html(index=False)\n",
    "t1 = t1.rsplit('\\n')\n",
    "t1.insert(1, cap)\n",
    "tab1 = ''\n",
    "for i, line in enumerate(t1):\n",
    "    tab1 += line\n",
    "    if i < (len(t1) - 1):\n",
    "        tab1 += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "\n",
       "<b> Table 1.</b> <em> Timing comparisons for tuple selection functions.</em>\n",
       "Mean computation times.\n",
       "\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n</th>\n",
       "      <th>tup_for</th>\n",
       "      <th>tup_for_adv</th>\n",
       "      <th>tup_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.102057</td>\n",
       "      <td>0.080149</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>11.484324</td>\n",
       "      <td>8.292516</td>\n",
       "      <td>0.011845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(tab1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, we nested two for loops in the original code snippet, and the code running time is extremely long when $n$ is large. In the advanced format, even though we keep nesting two for loops, but as we apply the list comprehensions and reduce the redundancy, the running time is a little improved. As for the third function, we only apply two for loop independently and introduce dictionary to achieve our goal and the running time is improved a lot according to Table 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this question we will use Pandas to read, clean, and append several data files from the National Health and Nutrition Examination Survey NHANES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### a) Read and append the demographic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The target of the function is to \n",
    "* Choose specific columns and rename the columns with literate variable names\n",
    "* Add an additional column identifying to which cohort each case belongs (\"years\" + \"datasets name\").\n",
    "* Cope with missing data and convert each column to an appropriate type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def pd_demographic(name, year):\n",
    "    '''\n",
    "    Read and append the '.XPT' file of demographic datasets.\n",
    "\n",
    "    This function will read the '.XPT' file and convert it to a DataFrame.\n",
    "    Several columns are selected and renamed according to the meaning of the\n",
    "    columns. Additional one column is added to the DataFrame and each column is\n",
    "    convert into a appropriate type. Finally the function will return the\n",
    "    processed DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str\n",
    "        The file's name.\n",
    "    year:  str\n",
    "        The conducted year of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Processed DataFrame.\n",
    "    '''\n",
    "    df = pd.read_sas(name)\n",
    "    columns = ['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \n",
    "               'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']\n",
    "    columns_add = ['unique id', 'age', 'race and ethnicity', 'education',\n",
    "            'marital status', 'interview/examination status', \n",
    "            'masked variance pseudo-psu', 'masked variance pseudo-stratum', \n",
    "            'sample exam weight', 'sample interview weight']\n",
    "    df = df[columns]\n",
    "    df = df.convert_dtypes()\n",
    "    for i in range(3):\n",
    "        df.iloc[:,i+3] = pd.Categorical(df.iloc[:,i+3])\n",
    "    df.columns = columns_add\n",
    "    cohort = 'NHANES' + ' ' + year\n",
    "    df1 = pd.DataFrame({'cohort':[cohort for i in range(len(df.index))]}, \n",
    "                       index=df.index)\n",
    "    df = pd.concat([df,df1], axis=1)             \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files directly from the website and apply the function abrove to each dataset and finally save the processed DataFrame into a pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://wwwn.cdc.gov/Nchs/Nhanes/'\n",
    "years = ['2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "names_1 = ['DEMO_G.XPT', 'DEMO_H.XPT', 'DEMO_I.XPT', 'DEMO_J.XPT']\n",
    "for i in range(4):\n",
    "    name = url + years[i] +'/' + names_1[i]\n",
    "    df = pd_demographic(name, years[i])\n",
    "    file_name = years[i] + ' ' + 'demographic.plk'\n",
    "    df.to_pickle(file_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### b) Read and append the  oral health and dentition data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part fairly do the same job as part a). One thing to mention is that I use regular expressionsin to find the columns with the format \"OHXXXCTC\" and \"OHXXXTC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_health(name, year):\n",
    "    '''\n",
    "    Read and append the '.XPT' file of oral health and dentition datasets.\n",
    "\n",
    "    This function will read the '.XPT' file and convert it to a DataFrame.\n",
    "    Several columns are selected and renamed according to the meaning of the\n",
    "    columns. Additional one column is added to the DataFrame and each column is\n",
    "    convert into a appropriate type. Finally the function will return the\n",
    "    processed DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str\n",
    "        The file's name.\n",
    "    year:  str\n",
    "        The conducted year of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Processed DataFrame.\n",
    "    '''\n",
    "    df = pd.read_sas(name)\n",
    "    columns_li = ['SEQN', 'OHDDESTS']\n",
    "    column_1 = r'OHX\\d\\dCTC'\n",
    "    column_2 = r'OHX\\d\\dTC'\n",
    "    columns_li.extend(\n",
    "        [m for m in df.columns if re.search(column_1,m) != None])\n",
    "    columns_li.extend(\n",
    "        [m for m in df.columns if re.search(column_2,m) != None])\n",
    "    df = df[columns_li]\n",
    "    columns_lower = [m.lower() for m in columns_li]\n",
    "    columns_lower[0] = 'unique id'\n",
    "    columns_lower[1] = 'dentition code'\n",
    "    df.columns = columns_lower\n",
    "    df1 = df.convert_dtypes()\n",
    "    for i in range(61):\n",
    "        df1.iloc[:,i+1] = pd.Categorical(df1.iloc[:,i+1])\n",
    "    cohort = 'NHANES' + ' ' + year\n",
    "    df2 = pd.DataFrame({'cohort':[cohort for i in range(len(df.index))]}, \n",
    "                       index=df.index)\n",
    "    df1 = pd.concat([df1,df2], axis=1)  \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files directly from the website and apply the function abrove to each dataset and finally save the processed DataFrame into a pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "url = 'https://wwwn.cdc.gov/Nchs/Nhanes/'\n",
    "years = ['2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "names_2 = ['OHXDEN_G.XPT', 'OHXDEN_H.XPT', 'OHXDEN_I.XPT', 'OHXDEN_J.XPT']\n",
    "for i in range(4):\n",
    "    name = url + years[i] +'/' + names_2[i]\n",
    "    df = pd_health(name, years[i])\n",
    "    file_name = years[i] + ' ' + 'oral health - dentition.plk'\n",
    "    df.to_pickle(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### c) Number of cases there are in the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this step I will read the data we saved in pickle format and then combine the dataset from different year together and reindex the DataFrame to calculate the number of cases in each datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# calculate cases in each dataset: --------------------------------------------\n",
    "df_demo = pd.concat([pd.read_pickle(years[i] + ' ' + 'demographic.plk')\n",
    "                     for i in range(4)])\n",
    "df_demo = df_demo.reset_index()\n",
    "df_demo = df_demo.drop(columns = ['index'])\n",
    "df_ohxden = pd.concat(\n",
    "    [pd.read_pickle(years[i] + ' ' + 'oral health - dentition.plk')\n",
    "     for i in range(4)\n",
    "     ]\n",
    ")\n",
    "df_ohxden = df_ohxden.reset_index()\n",
    "df_ohxden = df_ohxden.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "There are 39156 cases in the demographic datasets and 35909 cases in the ohxden datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39156, 11)\n",
      "(35909, 63)\n"
     ]
    }
   ],
   "source": [
    "print(df_demo.shape)\n",
    "print(df_ohxden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In the final step I will try to calculate the common cases shared by these two datasets according to 'unique id' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35909"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_id = np.array(df_demo['unique id'],dtype='int64')\n",
    "ohxden_id = np.array(df_ohxden['unique id'],dtype='int64')\n",
    "count_demo = np.bincount(demo_id)\n",
    "count_ohxden = np.bincount(ohxden_id)\n",
    "c = count_demo + count_ohxden\n",
    "count = [idx for idx, val in enumerate(c) if val == 2]\n",
    "len(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "There are 35909 cases are both in the demographic datasets and ohxden datasets."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
