{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 2, Solution\n",
    "**Stats 507, Fall 2021**\n",
    "*Dingyu Wang*\n",
    "*September 28, 2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The remaining questions will use the following imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# modules: --------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "# 79: -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this question we will use Pandas to read, clean, and append several data files from the National Health and Nutrition Examination Survey NHANES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### a) Read and append the demographic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The target of the function is to \n",
    "* Choose specific columns and rename the columns with literate variable names\n",
    "* Add an additional column identifying to which cohort each case belongs (\"years\" + \"datasets name\").\n",
    "* Cope with missing data and convert each column to an appropriate type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def pd_demographic(name, year):\n",
    "    '''\n",
    "    Read and append the '.XPT' file of demographic datasets.\n",
    "\n",
    "    This function will read the '.XPT' file and convert it to a DataFrame.\n",
    "    Several columns are selected and renamed according to the meaning of the\n",
    "    columns. Additional one column is added to the DataFrame and each column is\n",
    "    convert into a appropriate type. Finally the function will return the\n",
    "    processed DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str\n",
    "        The file's name.\n",
    "    year:  str\n",
    "        The conducted year of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Processed DataFrame.\n",
    "    '''\n",
    "    df = pd.read_sas(name)\n",
    "    columns = ['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', \n",
    "        'DMDMARTL', 'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']\n",
    "    columns_add = ['id', 'age', 'race', 'education',\n",
    "                   'marital_status', 'interview_status', \n",
    "                   'pseudo_psu', 'pseudo_stratum', \n",
    "                   'exam_wt', 'interview_wt']\n",
    "    df = df[columns]\n",
    "    df = df.convert_dtypes()\n",
    "    for i in range(3):\n",
    "        df.iloc[:,i+3] = pd.Categorical(df.iloc[:,i+3])\n",
    "    df.columns = columns_add\n",
    "    cohort = 'NHANES' + ' ' + year\n",
    "    df1 = pd.DataFrame({'cohort':[cohort for i in range(len(df.index))]}, \n",
    "                       index=df.index)\n",
    "    df = pd.concat([df,df1], axis=1)             \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files directly from the website and apply the function abrove to each dataset and finally save the processed DataFrame into a pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://wwwn.cdc.gov/Nchs/Nhanes/'\n",
    "years = ['2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "names_1 = ['DEMO_G.XPT', 'DEMO_H.XPT', 'DEMO_I.XPT', 'DEMO_J.XPT']\n",
    "for i in range(4):\n",
    "    name = url + years[i] +'/' + names_1[i]\n",
    "    df = pd_demographic(name, years[i])\n",
    "    file_name = years[i] + ' ' + 'demographic.pickle'\n",
    "    df.to_pickle(file_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### b) Read and append the  oral health and dentition data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part fairly do the same job as part a). One thing to mention is that I use regular expressionsin to find the columns with the format \"OHXXXCTC\" and \"OHXXXTC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_health(name, year):\n",
    "    '''\n",
    "    Read and append the '.XPT' file of oral health and dentition datasets.\n",
    "\n",
    "    This function will read the '.XPT' file and convert it to a DataFrame.\n",
    "    Several columns are selected and renamed according to the meaning of the\n",
    "    columns. Additional one column is added to the DataFrame and each column is\n",
    "    convert into a appropriate type. Finally the function will return the\n",
    "    processed DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str\n",
    "        The file's name.\n",
    "    year:  str\n",
    "        The conducted year of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Processed DataFrame.\n",
    "    '''\n",
    "    df = pd.read_sas(name)\n",
    "    columns_li = ['SEQN', 'OHDDESTS']\n",
    "    column_1 = r'OHX\\d\\dCTC'\n",
    "    column_2 = r'OHX\\d\\dTC'\n",
    "    columns_li.extend(\n",
    "        [m for m in df.columns if re.search(column_1,m) != None])\n",
    "    columns_li.extend(\n",
    "        [m for m in df.columns if re.search(column_2,m) != None])\n",
    "    df = df[columns_li]\n",
    "    columns_lower = [m.lower() for m in columns_li]\n",
    "    columns_lower[0] = 'id'\n",
    "    columns_lower[1] = 'dentition_code'\n",
    "    df.columns = columns_lower\n",
    "    df1 = df.convert_dtypes()\n",
    "    for i in range(61):\n",
    "        df1.iloc[:,i+1] = pd.Categorical(df1.iloc[:,i+1])\n",
    "    cohort = 'NHANES' + ' ' + year\n",
    "    df2 = pd.DataFrame({'cohort':[cohort for i in range(len(df.index))]}, \n",
    "                       index=df.index)\n",
    "    df1 = pd.concat([df1,df2], axis=1)  \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files directly from the website and apply the function abrove to each dataset and finally save the processed DataFrame into a pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\python\\lib\\site-packages\\pandas\\io\\sas\\sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    }
   ],
   "source": [
    "url = 'https://wwwn.cdc.gov/Nchs/Nhanes/'\n",
    "years = ['2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "names_2 = ['OHXDEN_G.XPT', 'OHXDEN_H.XPT', 'OHXDEN_I.XPT', 'OHXDEN_J.XPT']\n",
    "for i in range(4):\n",
    "    name = url + years[i] +'/' + names_2[i]\n",
    "    df = pd_health(name, years[i])\n",
    "    file_name = years[i] + ' ' + 'oral health - dentition.pickle'\n",
    "    df.to_pickle(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### c) Number of cases there are in the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this step I will read the data we saved in pickle format and then combine the dataset from different year together and reindex the DataFrame to calculate the number of cases in each datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# calculate cases in each dataset: --------------------------------------------\n",
    "df_demo = pd.concat([pd.read_pickle(years[i] + ' ' + 'demographic.pickle')\n",
    "                     for i in range(4)])\n",
    "df_demo = df_demo.reset_index()\n",
    "df_demo = df_demo.drop(columns = ['index'])\n",
    "df_ohxden = pd.concat(\n",
    "    [pd.read_pickle(years[i] + ' ' + 'oral health - dentition.pickle')\n",
    "     for i in range(4)\n",
    "     ]\n",
    ")\n",
    "df_ohxden = df_ohxden.reset_index()\n",
    "df_ohxden = df_ohxden.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "There are 39156 cases in the demographic datasets and 35909 cases in the ohxden datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39156, 11)\n",
      "(35909, 63)\n"
     ]
    }
   ],
   "source": [
    "print(df_demo.shape)\n",
    "print(df_ohxden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In the final step I will try to calculate the common cases shared by these two datasets according to 'unique id' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_id = np.array(df_demo['id'],dtype='int64')\n",
    "ohxden_id = np.array(df_ohxden['id'],dtype='int64')\n",
    "count_demo = np.bincount(demo_id)\n",
    "count_ohxden = np.bincount(ohxden_id)\n",
    "c = count_demo + count_ohxden\n",
    "count = [idx for idx, val in enumerate(c) if val == 2]\n",
    "len(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "There are 35909 cases are both in the demographic datasets and ohxden datasets."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
